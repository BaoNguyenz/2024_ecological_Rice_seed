{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import feature\n",
    "import re\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 (OpenCV): 4.10.0\n",
      "numpy: 1.26.3\n",
      "pandas: 2.2.2\n",
      "scipy: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import __version__ as scipy_version\n",
    "\n",
    "# Collect versions\n",
    "versions = {\n",
    "    \"cv2 (OpenCV)\": cv2.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"scipy\": scipy_version,\n",
    "}\n",
    "\n",
    "# Print versions\n",
    "for lib, version in versions.items():\n",
    "    print(f\"{lib}: {version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort and read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "def read_image_data(folder_path):\n",
    "    image_names = sorted(os.listdir(folder_path), key=natural_sort_key)\n",
    "    if not image_names:\n",
    "        print(\"No images found in the directory.\")\n",
    "        return []\n",
    "    elif len(image_names) > 2:\n",
    "        print(f\"The names of the first three images in the directory are: {image_names[0]}, {image_names[1]}, {image_names[2]}\")\n",
    "    else:\n",
    "        print(\"Not enough images to display three names.\")\n",
    "    image_paths = [os.path.join(folder_path, name) for name in image_names]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features(image_paths):\n",
    "    features = []\n",
    "    for image_path in tqdm(image_paths):\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "            continue\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, img_bin = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "        label_img = label(img_bin)\n",
    "        props = regionprops(label_img)\n",
    "        if props:\n",
    "            largest_prop = max(props, key=lambda x: x.area)\n",
    "            features.append([os.path.basename(image_path)] + [\n",
    "                largest_prop.area,\n",
    "                largest_prop.bbox[3] - largest_prop.bbox[1],\n",
    "                largest_prop.bbox[2] - largest_prop.bbox[0],\n",
    "                (largest_prop.bbox[3] - largest_prop.bbox[1]) / (largest_prop.bbox[2] - largest_prop.bbox[0]) if (largest_prop.bbox[2] - largest_prop.bbox[0]) != 0 else 0,\n",
    "                largest_prop.major_axis_length,\n",
    "                largest_prop.minor_axis_length,\n",
    "                largest_prop.convex_area,\n",
    "                cv2.arcLength(np.array(largest_prop.coords), closed=True),\n",
    "                np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 0]),\n",
    "                np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 1]),\n",
    "                np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 2]),\n",
    "                np.sqrt(np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 0])),\n",
    "                np.sqrt(np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 1])),\n",
    "                np.sqrt(np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1], 2])),\n",
    "                np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]]),\n",
    "                np.std(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]]),\n",
    "                np.sum((img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]] - np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]])) ** 2),\n",
    "                np.sum((img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]] - np.mean(img[largest_prop.coords[:, 0], largest_prop.coords[:, 1]])) ** 3),\n",
    "            ])\n",
    "        else:\n",
    "            features.append([os.path.basename(image_path)] + [np.nan] * 18 )\n",
    "\n",
    "    df = pd.DataFrame(features, columns=['Name', 'area', 'length', 'width', 'length_width_ratio', 'major_axis_length',\n",
    "                                         'minor_axis_length', 'convex_area', 'perimeter', 'r_mean', 'g_mean', 'b_mean',\n",
    "                                         'rs', 'gs', 'bs', 'mean', 'std_dev', 'uniformity', 'third_moment',])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LBP_features(image_paths):\n",
    "    data = []\n",
    "    points = 8\n",
    "    radius = 1\n",
    "    for image_path in tqdm(image_paths):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            lbp = feature.local_binary_pattern(image, points, radius, method=\"uniform\")\n",
    "            (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, points + 3), range=(0, points + 2))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            hist_series = pd.Series(hist, name=os.path.basename(image_path))\n",
    "            data.append(hist_series)\n",
    "        else:\n",
    "            print(f\"Failed to read {image_path}\")\n",
    "            data.append(pd.Series([np.nan]*10, name=os.path.basename(image_path)))\n",
    "    lbp_df = pd.DataFrame(data).reset_index().rename(columns={\"index\": \"Name\"})\n",
    "    lbp_df.columns = [\"Name\"] + [f\"LBP_{i+1}\" for i in range(len(lbp_df.columns) - 1)]\n",
    "    return lbp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIST feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gist_features(image_paths, orientations=8, blocks=4):\n",
    "    descriptors = []\n",
    "    for path in tqdm(image_paths):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {path}\")\n",
    "            descriptors.append([os.path.basename(path)] + [np.nan]*(orientations*blocks*blocks))\n",
    "            continue\n",
    "        height, width = img.shape\n",
    "        cell_size = min(height, width) // blocks\n",
    "        gx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        gradient_magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        gradient_orientation = np.arctan2(gy, gx) * (180 / np.pi) + 180\n",
    "        gradient_orientation_bins = np.floor(gradient_orientation / (360 / orientations)).astype(int)\n",
    "        descriptor = np.zeros(orientations * blocks * blocks)\n",
    "        for i in range(blocks):\n",
    "            for j in range(blocks):\n",
    "                cell_hist = np.zeros(orientations)\n",
    "                for ii in range(cell_size):\n",
    "                    for jj in range(cell_size):\n",
    "                        x = i * cell_size + ii\n",
    "                        y = j * cell_size + jj\n",
    "                        if x >= height or y >= width:\n",
    "                            continue\n",
    "                        bin_idx = gradient_orientation_bins[x, y] % orientations\n",
    "                        cell_hist[bin_idx] += gradient_magnitude[x, y]\n",
    "                descriptor[(i * blocks + j) * orientations:(i * blocks + j + 1) * orientations] = cell_hist\n",
    "        descriptor /= (np.sum(descriptor) + 1e-7)\n",
    "        descriptors.append([os.path.basename(path)] + descriptor.tolist())\n",
    "    gist_df = pd.DataFrame(descriptors, columns=['Name'] + [f'GIST_{i}' for i in range(orientations * blocks * blocks)])\n",
    "    return gist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLCM feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM_all(image_paths, distance=3):\n",
    "\n",
    "    list_GLCM = []\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    for image_path in tqdm(image_paths):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "            continue\n",
    "        if len(img.shape) == 3:  \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        glcm = graycomatrix(img, [distance], angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "        features = []\n",
    "        for angle_idx in range(len(angles)):\n",
    "            features.extend([\n",
    "                graycoprops(glcm, 'contrast')[0, angle_idx],\n",
    "                graycoprops(glcm, 'correlation')[0, angle_idx],\n",
    "                graycoprops(glcm, 'energy')[0, angle_idx],\n",
    "                graycoprops(glcm, 'homogeneity')[0, angle_idx]\n",
    "            ])\n",
    "\n",
    "        columns = [f\"{prop}_{int(np.degrees(angle))}\" for prop in ('contrast', 'correlation', 'energy', 'homogeneity') for angle in angles]\n",
    "        features_df = pd.DataFrame([features], columns=columns)\n",
    "        # features_df['Name'] = os.path.basename(image_path)\n",
    "        features_df.insert(0, 'Name', os.path.basename(image_path))\n",
    "        list_GLCM.append(features_df)\n",
    "    \n",
    "    glcm_df = pd.concat(list_GLCM, ignore_index=True)\n",
    "    return glcm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r''\n",
    "image_paths = read_image_data(folder_path)\n",
    "glcm_features_df = GLCM_all(image_paths)\n",
    "basic_features_df = extract_basic_features(image_paths)\n",
    "lbp_features_df = extract_LBP_features(image_paths)\n",
    "gist_features_df = extract_gist_features(image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
