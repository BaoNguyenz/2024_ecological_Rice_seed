{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\PROJECTWORSHOP\\ICIIT2024\\CSV_data\\Basic_GLCM_LBP_GIST\\BC-15++.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "X.shape[1], y_encoded.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "importances_rf =rf_model.feature_importances_\n",
    "indices_dt = np.argsort(importances_rf)[::-1]\n",
    "features_dt = X.columns[indices_dt]\n",
    "\n",
    "for i in range(len(importances_rf)):\n",
    "    print(f'feature {features_dt[i]:}: {importances_rf[indices_dt[i]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranking_rf = 86\n",
    "top_features_rf = features_dt[:top_ranking_rf]\n",
    "\n",
    "X_train_rf = X_train[top_features_rf]\n",
    "X_test_rf = X_test[top_features_rf]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_rf = scaler.fit_transform(X_train_rf)\n",
    "X_test_scaled_rf = scaler.fit_transform(X_test_rf)\n",
    "\t\n",
    "top_features_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 30\n",
    "top_features = features_dt[:top_n]\n",
    "top_importances = importances_rf[indices_dt[:top_n]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), top_importances[::-1], align='center')\n",
    "plt.yticks(range(top_n), top_features[::-1])\n",
    "# plt.xlabel('Feature Importance')\n",
    "# plt.title('Top 30 Important Features (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=300, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_rf = np.vstack((X_train_scaled_rf, X_test_scaled_rf))\n",
    "y_combined_rf = np.hstack((y_train, y_test))\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    \n",
    "    for _ in tqdm(range(1)):\n",
    "        combined_df_rf = pd.DataFrame(X_combined_rf)\n",
    "        combined_df_rf['target'] = y_combined_rf\n",
    "\n",
    "        shuffled_df_rf = combined_df_rf.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        X_shuffled_rf = shuffled_df_rf.drop(columns=['target']).values\n",
    "        y_shuffled_rf = shuffled_df_rf['target'].values\n",
    "\n",
    "        X_train_shuffled_rf = X_shuffled_rf[:len(X_train_scaled_rf)]\n",
    "        y_train_shuffled_rf = y_shuffled_rf[:len(y_train)]\n",
    "        X_test_shuffled_rf = X_shuffled_rf[len(X_train_scaled_rf):]\n",
    "        y_test_shuffled_rf = y_shuffled_rf[len(y_train):]\n",
    "\n",
    "        clf.fit(X_train_shuffled_rf, y_train_shuffled_rf)\n",
    "        y_pred = clf.predict(X_test_shuffled_rf)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test_shuffled_rf, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_shuffled_rf, y_pred, average='weighted'))\n",
    "\n",
    "    min_accuracy = np.min(accuracies)\n",
    "    max_accuracy = np.max(accuracies)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1_score = np.max(f1_scores)\n",
    "      \n",
    "    results[name] = (min_accuracy, max_accuracy, avg_accuracy, avg_f1_score)\n",
    "    \n",
    "    print(f'{name} - Min Accuracy: {min_accuracy:.4f}, Max Accuracy: {max_accuracy:.4f}, Average Accuracy: {avg_accuracy:.4f}, Average F1 Score: {avg_f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffled_rf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desition Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "importances_dt = dt_model.feature_importances_\n",
    "indices_dt = np.argsort(importances_dt)[::-1]\n",
    "features_dt = X.columns[indices_dt]\n",
    "\n",
    "for i in range(len(importances_dt)):\n",
    "    print(f'feature {features_dt[i]:}: {importances_dt[indices_dt[i]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranking_dt = 86\n",
    "top_features_dt = features_dt[:top_ranking_dt]\n",
    "\n",
    "X_train_dt = X_train[top_features_dt]\n",
    "X_test_dt = X_test[top_features_dt]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_dt = scaler.fit_transform(X_train_dt)\n",
    "X_test_scaled_dt = scaler.fit_transform(X_test_dt)\n",
    "\n",
    "top_features_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_dt = np.vstack((X_train_scaled_dt, X_test_scaled_dt))\n",
    "y_combined_dt = np.hstack((y_train, y_test))\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    for _ in tqdm(range(1)):\n",
    "        combined_df_dt = pd.DataFrame(X_combined_dt)\n",
    "        combined_df_dt['target'] = y_combined_dt\n",
    "\n",
    "        shuffled_df_dt = combined_df_dt.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        X_shuffled_dt = shuffled_df_dt.drop(columns=['target']).values\n",
    "        y_shuffled_dt = shuffled_df_dt['target'].values\n",
    "\n",
    "        X_train_shuffled_dt = X_shuffled_dt[:len(X_train_scaled_dt)]\n",
    "        y_train_shuffled_dt = y_shuffled_dt[:len(y_train)]\n",
    "        X_test_shuffled_dt = X_shuffled_dt[len(X_train_scaled_dt):]\n",
    "        y_test_shuffled_dt = y_shuffled_dt[len(y_train):]\n",
    "\n",
    "        clf.fit(X_train_shuffled_dt, y_train_shuffled_dt)\n",
    "        y_pred = clf.predict(X_test_shuffled_dt)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test_shuffled_dt, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_shuffled_dt, y_pred, average='weighted'))\n",
    "\n",
    "    min_accuracy = np.min(accuracies)\n",
    "    max_accuracy = np.max(accuracies)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    results[name] = (min_accuracy, max_accuracy, avg_accuracy, avg_f1_score)\n",
    "    print(f'{name} - Min Accuracy: {min_accuracy:.4f}, Max Accuracy: {max_accuracy:.4f}, Average Accuracy: {avg_accuracy:.4f}, Average F1 Score: {avg_f1_score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
